{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Assignment 1C - Question 2\n",
    "## Semantic Person Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import numpy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorboard import notebook\n",
    "from tensorflow.keras.preprocessing.image import Iterator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydot\n",
    "import IPython\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('CAB420_Assessment_1C_Data/Data/Q2/Q2/Train_Data/Train.csv')\n",
    "test = pd.read_csv('CAB420_Assessment_1C_Data/Data/Q2/Q2/Test_Data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "gnd_img = []\n",
    "files = glob.glob('CAB420_Assessment_1C_Data/Data/Q2/Q2/Train_Data/Originals/*.png')\n",
    "for myfile in files:\n",
    "    image = cv2.imread(myfile, 0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gnd_img.append(myfile[58:])\n",
    "    train_img.append(image)\n",
    "\n",
    "#train_img = np.array(train_img)\n",
    "gnd_img = np.array(gnd_img)\n",
    "\n",
    "#print('Training shape: ', train_img.shape)\n",
    "#print('Training gnd: ', gnd_img[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_originals = []\n",
    "gnd_test = []\n",
    "files = glob.glob('CAB420_Assessment_1C_Data/Data/Q2/Q2/Test_Data/Originals/*.png')\n",
    "for myfile in files:\n",
    "    image = cv2.imread(myfile)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gnd_test.append(myfile[57:])\n",
    "    test_originals.append(image)\n",
    "\n",
    "#test_originals = np.array(test_originals)\n",
    "gnd_test = np.array(gnd_test)\n",
    "#print('Testing shape: ', test_originals.shape)\n",
    "#print('Testing gnd: ', gnd_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['torcol2','torcol3','tortex','torcol3','legcol2','legcol3','legtex','pose'])\n",
    "train_gender = train.iloc[:1]\n",
    "train_tortyp = train.iloc[:2]\n",
    "train_torcol = train.iloc[:3]\n",
    "train_legtyp = train.iloc[:4]\n",
    "train_legcol = train.iloc[:5]\n",
    "train_luggage = train.iloc[:6] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['torcol2','torcol3','tortex','torcol3','legcol2','legcol3','legtex','pose'])\n",
    "test_gender = test.iloc[:1]\n",
    "test_tortyp = test.iloc[:2]\n",
    "test_torcol = test.iloc[:3]\n",
    "test_legtyp = test.iloc[:4]\n",
    "test_legcol = test.iloc[:5]\n",
    "test_luggage = test.iloc[:6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=[20, 20])\n",
    "#for i in range(100):\n",
    "#    ax = fig.add_subplot(10, 10, i + 1)\n",
    "#    ax.imshow(test_originals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"A1CQ2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nimg (InputLayer)                [(None, 144, 226, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 142, 224, 8)  224         img[0][0]                        \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 71, 112, 8)   0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 69, 110, 16)  1168        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 34, 55, 16)   0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 53, 32)   4640        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 54272)        0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ngender_out (Dense)              (None, 3)            195         dense[0][0]                      \n__________________________________________________________________________________________________\ntortyp_out (Dense)              (None, 3)            195         dense_1[0][0]                    \n__________________________________________________________________________________________________\ntorcol_out (Dense)              (None, 11)           715         dense_2[0][0]                    \n__________________________________________________________________________________________________\nlegtyp_out (Dense)              (None, 3)            195         dense_3[0][0]                    \n__________________________________________________________________________________________________\nlegocol_out (Dense)             (None, 11)           715         dense_4[0][0]                    \n__________________________________________________________________________________________________\nluggage_out (Dense)             (None, 3)            195         dense_5[0][0]                    \n==================================================================================================\nTotal params: 20,849,074\nTrainable params: 20,849,074\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(144, 226, 3, ), name='img')\n",
    "x = layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x1 = layers.Dense(64, activation='relu')(x)\n",
    "gender = layers.Dense(3, name='gender_out')(x1)\n",
    "\n",
    "x2 = layers.Dense(64, activation='relu')(x)\n",
    "tortyp = layers.Dense(3, name='tortyp_out')(x2)\n",
    "\n",
    "x3 = layers.Dense(64, activation='relu')(x)\n",
    "torcol = layers.Dense(11, name='torcol_out')(x3)\n",
    "\n",
    "x4 = layers.Dense(64, activation='relu')(x)\n",
    "legtyp = layers.Dense(3, name='legtyp_out')(x4)\n",
    "\n",
    "x5 = layers.Dense(64, activation='relu')(x)\n",
    "legcol = layers.Dense(11, name='legocol_out')(x5)\n",
    "\n",
    "x6 = layers.Dense(64, activation='relu')(x)\n",
    "luggage = layers.Dense(3, name='luggage_out')(x6)\n",
    "\n",
    "model_cnn = keras.Model(inputs=inputs, outputs=[gender,tortyp,torcol,legtyp,legcol,luggage], name='A1CQ2')\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(loss=['mean_squared_error', keras.losses.SparseCategoricalCrossentropy(from_logits=True)],\n",
    "              optimizer=keras.optimizers.RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 226, 207, 220, 188, 249, 193, 275, 145, 206, 393, 231, 155, 189, 190, 216, 202, 171, 233, 189, 172, 157, 187, 257, 204, 225, 167, 180, 191, 240, 214, 209, 199, 191, 205, 145, 219, 179, 218, 188, 205, 210, 179, 188, 211, 197, 181, 236, 186, 166, 218, 150, 187, 182, 166, 229, 204, 157, 250, 216, 239, 212, 179, 187, 295, 159, 188, 187, 213, 188, 249, 199, 273, 185, 187, 153, 188, 178, 177, 244, 234, 243, 207, 198, 199, 249, 228, 200, 190, 260, 257, 201, 217, 219, 248, 244, 231, 155, 191, 228, 208, 247, 212, 230, 196, 207, 224, 257, 248, 176, 219, 222, 223, 221, 214, 211, 168, 214, 270, 243, 236, 200, 180, 192, 189, 178, 228, 189, 222, 192, 138, 170, 209, 199, 182, 214, 338, 307, 210, 204, 269, 211, 210, 186, 214, 213, 215, 188, 163, 194, 280, 200, 220, 210, 177, 300, 256, 176, 194, 209, 184, 214, 199, 202, 194, 279, 210, 249, 181, 188, 294, 218, 190, 221, 293, 176, 168, 207, 201, 204, 206, 233, 231, 273, 345, 353, 253, 142, 189, 177, 193, 224, 228, 199, 221, 290, 257, 189, 278, 313, 229, 223, 242, 234, 203, 209, 177, 174, 131, 157, 300, 271, 219, 158, 244, 190, 319, 154, 203, 209, 221, 285, 197, 223, 223, 252, 298, 249, 244, 220, 215, 221, 266, 287, 268, 247, 274, 262, 242, 224, 284, 273, 244, 262, 283, 211, 299, 271, 247, 261, 237, 256, 243, 255, 247, 269, 266, 249, 243, 257, 290, 274, 251, 273, 222, 237, 248, 247, 264, 247, 245, 238, 248, 245, 231, 237, 206, 239, 211, 219, 230, 237, 224, 232, 203, 222, 210, 213, 185, 210, 263, 242, 234, 261, 257, 233, 279, 236, 218, 242, 231, 228, 257, 268, 384, 327, 227, 298, 348, 325, 309, 395, 376, 253, 340, 388, 408, 333, 347, 349, 329, 334, 302, 309, 306, 301, 343, 290, 299, 418, 352, 352, 335, 231, 350, 312, 376, 321, 317, 267, 234, 251, 304, 291, 376, 342, 328, 409, 338, 319, 308, 314, 341, 314, 401, 315, 353, 401, 290, 393, 367, 295, 324, 317, 317, 351, 294, 333, 333, 287, 309, 355, 321, 299, 362, 294, 321, 344, 297, 314, 384, 299, 285, 331, 316, 379, 299, 353, 322, 321, 346, 299, 280, 326, 313, 372, 414, 413, 218, 288, 293, 291, 316, 313, 258, 308, 303, 293, 294, 355, 366, 323, 354, 343, 285, 251, 410, 286, 296, 326, 335, 276, 366, 302, 289, 302, 303, 276, 333, 288, 303, 267, 306, 273, 378, 315, 361, 288, 261, 306, 241, 363, 350, 287, 321, 298, 383, 348, 396, 251, 349, 429, 277, 302, 349, 262, 209, 234, 273, 237, 249, 300, 269, 270, 229, 274, 262, 250, 282, 203, 299, 212, 247, 230, 247, 218, 250, 230, 194, 232, 264, 308, 238, 240, 262, 193, 266, 284, 265, 171, 255, 266, 280, 269, 209, 243, 244, 154, 192, 113, 200, 196, 116, 108, 226, 176, 183, 229, 217, 198, 217, 205, 265, 133, 243, 255, 168, 254, 222, 241, 252\n  y sizes: 1, 2, 3, 4, 5, 6\nMake sure all arrays contain the same number of samples.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1c4b0e764ac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model_cnn.fit(train_img, [train_gender, train_tortyp,train_torcol,train_legtyp,train_legcol,train_luggage],\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     validation_data=(test_originals, [test_gender, test_tortyp, test_torcol, test_legtyp, test_legcol, test_luggage]))\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1134\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1155\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1628\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[0;32m   1629\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 226, 207, 220, 188, 249, 193, 275, 145, 206, 393, 231, 155, 189, 190, 216, 202, 171, 233, 189, 172, 157, 187, 257, 204, 225, 167, 180, 191, 240, 214, 209, 199, 191, 205, 145, 219, 179, 218, 188, 205, 210, 179, 188, 211, 197, 181, 236, 186, 166, 218, 150, 187, 182, 166, 229, 204, 157, 250, 216, 239, 212, 179, 187, 295, 159, 188, 187, 213, 188, 249, 199, 273, 185, 187, 153, 188, 178, 177, 244, 234, 243, 207, 198, 199, 249, 228, 200, 190, 260, 257, 201, 217, 219, 248, 244, 231, 155, 191, 228, 208, 247, 212, 230, 196, 207, 224, 257, 248, 176, 219, 222, 223, 221, 214, 211, 168, 214, 270, 243, 236, 200, 180, 192, 189, 178, 228, 189, 222, 192, 138, 170, 209, 199, 182, 214, 338, 307, 210, 204, 269, 211, 210, 186, 214, 213, 215, 188, 163, 194, 280, 200, 220, 210, 177, 300, 256, 176, 194, 209, 184, 214, 199, 202, 194, 279, 210, 249, 181, 188, 294, 218, 190, 221, 293, 176, 168, 207, 201, 204, 206, 233, 231, 273, 345, 353, 253, 142, 189, 177, 193, 224, 228, 199, 221, 290, 257, 189, 278, 313, 229, 223, 242, 234, 203, 209, 177, 174, 131, 157, 300, 271, 219, 158, 244, 190, 319, 154, 203, 209, 221, 285, 197, 223, 223, 252, 298, 249, 244, 220, 215, 221, 266, 287, 268, 247, 274, 262, 242, 224, 284, 273, 244, 262, 283, 211, 299, 271, 247, 261, 237, 256, 243, 255, 247, 269, 266, 249, 243, 257, 290, 274, 251, 273, 222, 237, 248, 247, 264, 247, 245, 238, 248, 245, 231, 237, 206, 239, 211, 219, 230, 237, 224, 232, 203, 222, 210, 213, 185, 210, 263, 242, 234, 261, 257, 233, 279, 236, 218, 242, 231, 228, 257, 268, 384, 327, 227, 298, 348, 325, 309, 395, 376, 253, 340, 388, 408, 333, 347, 349, 329, 334, 302, 309, 306, 301, 343, 290, 299, 418, 352, 352, 335, 231, 350, 312, 376, 321, 317, 267, 234, 251, 304, 291, 376, 342, 328, 409, 338, 319, 308, 314, 341, 314, 401, 315, 353, 401, 290, 393, 367, 295, 324, 317, 317, 351, 294, 333, 333, 287, 309, 355, 321, 299, 362, 294, 321, 344, 297, 314, 384, 299, 285, 331, 316, 379, 299, 353, 322, 321, 346, 299, 280, 326, 313, 372, 414, 413, 218, 288, 293, 291, 316, 313, 258, 308, 303, 293, 294, 355, 366, 323, 354, 343, 285, 251, 410, 286, 296, 326, 335, 276, 366, 302, 289, 302, 303, 276, 333, 288, 303, 267, 306, 273, 378, 315, 361, 288, 261, 306, 241, 363, 350, 287, 321, 298, 383, 348, 396, 251, 349, 429, 277, 302, 349, 262, 209, 234, 273, 237, 249, 300, 269, 270, 229, 274, 262, 250, 282, 203, 299, 212, 247, 230, 247, 218, 250, 230, 194, 232, 264, 308, 238, 240, 262, 193, 266, 284, 265, 171, 255, 266, 280, 269, 209, 243, 244, 154, 192, 113, 200, 196, 116, 108, 226, 176, 183, 229, 217, 198, 217, 205, 265, 133, 243, 255, 168, 254, 222, 241, 252\n  y sizes: 1, 2, 3, 4, 5, 6\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "history = model_cnn.fit(train_img, [train_gender, train_tortyp,train_torcol,train_legtyp,train_legcol,train_luggage],\n",
    "                    batch_size=64,\n",
    "                    epochs=20,\n",
    "                    validation_data=(test_originals, [test_gender, test_tortyp, test_torcol, test_legtyp, test_legcol, test_luggage]))"
   ]
  }
 ]
}
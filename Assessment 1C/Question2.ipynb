{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Assignment 1C - Question 2\n",
    "## Semantic Person Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import numpy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorboard import notebook\n",
    "from tensorflow.keras.preprocessing.image import Iterator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydot\n",
    "import IPython\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('CAB420_Assessment_1C_Data/Data/Q2/Q2/Train_Data/Train.csv')\n",
    "test = pd.read_csv('CAB420_Assessment_1C_Data/Data/Q2/Q2/Test_Data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training shape:  (520,)\n",
      "Training gnd:  ['A_0001_01_083.png' 'A_0001_03_126.png' 'A_0001_05_051.png'\n",
      " 'A_0002_01_021.png' 'A_0002_04_011.png' 'A_0002_08_051.png'\n",
      " 'A_0003_03_131.png' 'A_0003_04_026.png' 'A_0003_08_091.png']\n",
      "<ipython-input-3-f4c1eb5ab4d3>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  train_img = np.array(train_img)\n"
     ]
    }
   ],
   "source": [
    "train_img = []\n",
    "gnd_img = []\n",
    "files = glob.glob('CAB420_Assessment_1C_Data/Data/Q2/Q2/Train_Data/Originals/*.png')\n",
    "for myfile in files:\n",
    "    image = cv2.imread(myfile, 0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gnd_img.append(myfile[58:])\n",
    "    train_img.append(image)\n",
    "\n",
    "train_img = np.array(train_img)\n",
    "gnd_img = np.array(gnd_img)\n",
    "\n",
    "print('Training shape: ', train_img.shape)\n",
    "print('Training gnd: ', gnd_img[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-4-1cf7ccf836f0>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  test_originals = np.array(test_originals)\n",
      "Testing shape:  (196,)\n",
      "Testing gnd:  ['cam3-2_frame_2500_pos_419_514_86_253.png'\n",
      " 'cam3-2_frame_4000_pos_457_520_110_276.png'\n",
      " 'cam3-2_frame_7750_pos_348_432_159_358.png'\n",
      " 'cam3_frame_17250_pos_295_380_292_496.png'\n",
      " 'cam3_frame_19000_pos_400_505_215_423.png'\n",
      " 'cam3_frame_23750_pos_416_502_134_319.png'\n",
      " 'cam3_frame_24250_pos_361_469_233_465.png'\n",
      " 'cam3_frame_25750_pos_355_455_158_342.png'\n",
      " 'cam3_frame_33000_pos_316_412_160_354.png']\n"
     ]
    }
   ],
   "source": [
    "test_originals = []\n",
    "gnd_test = []\n",
    "files = glob.glob('CAB420_Assessment_1C_Data/Data/Q2/Q2/Test_Data/Originals/*.png')\n",
    "for myfile in files:\n",
    "    image = cv2.imread(myfile)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gnd_test.append(myfile[57:])\n",
    "    test_originals.append(image)\n",
    "\n",
    "test_originals = np.array(test_originals)\n",
    "gnd_test = np.array(gnd_test)\n",
    "print('Testing shape: ', test_originals.shape)\n",
    "print('Testing gnd: ', gnd_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['torcol2','torcol3','tortex','torcol3','legcol2','legcol3','legtex','pose'])\n",
    "train_gender = train.iloc[:1]\n",
    "train_tortyp = train.iloc[:2]\n",
    "train_torcol = train.iloc[:3]\n",
    "train_legtyp = train.iloc[:4]\n",
    "train_legcol = train.iloc[:5]\n",
    "train_luggage = train.iloc[:6] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              filename  gender  tortyp  \\\n0    ip54-subjects_frame_14800_pos_478_703_223_649.png       0       1   \n1    ip53-subjects_frame_52600_pos_516_701_242_627.png       0       1   \n2    ip70-subjects_frame_164400_pos_193_294_127_384...       0       1   \n3     ip53-subjects_frame_7600_pos_638_783_169_453.png       1       0   \n4    ip53-subjects_frame_61600_pos_520_700_283_681.png       1       1   \n..                                                 ...     ...     ...   \n191            cam8_frame_58750_pos_269_365_92_303.png       0       0   \n192  ip70-subjects_frame_43800_pos_779_948_291_601.png       1       1   \n193  ip54-subjects_frame_183400_pos_308_506_196_521...       0       0   \n194   ip70-subjects_frame_82200_pos_825_927_75_290.png       0       1   \n195  ip53-subjects_frame_50800_pos_471_638_176_481.png       0       1   \n\n     torcol  legtyp  legcol  luggage  \n0         8       1       1        0  \n1         1       0       4        1  \n2         9       1       7        0  \n3         4       0       1        0  \n4         8       1       0        0  \n..      ...     ...     ...      ...  \n191      10       0       0        1  \n192       9       1       1        0  \n193       0       0       0        1  \n194      10       0       1        0  \n195       4       0       1        0  \n\n[196 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "test = test.drop(columns=['torcol2','torcol3','tortex','torcol3','legcol2','legcol3','legtex','pose'])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=[20, 20])\n",
    "#for i in range(100):\n",
    "#    ax = fig.add_subplot(10, 10, i + 1)\n",
    "#    ax.imshow(test_originals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"A1CQ2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nimg (InputLayer)                [(None, 144, 226, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 142, 224, 8)  224         img[0][0]                        \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 71, 112, 8)   0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 69, 110, 16)  1168        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 34, 55, 16)   0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 53, 32)   4640        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 54272)        0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 64)           3473472     flatten[0][0]                    \n__________________________________________________________________________________________________\ngender_out (Dense)              (None, 3)            195         dense[0][0]                      \n__________________________________________________________________________________________________\ntortyp_out (Dense)              (None, 3)            195         dense_1[0][0]                    \n__________________________________________________________________________________________________\ntorcol_out (Dense)              (None, 11)           715         dense_2[0][0]                    \n__________________________________________________________________________________________________\nlegtyp_out (Dense)              (None, 3)            195         dense_3[0][0]                    \n__________________________________________________________________________________________________\nlegocol_out (Dense)             (None, 11)           715         dense_4[0][0]                    \n__________________________________________________________________________________________________\nluggage_out (Dense)             (None, 3)            195         dense_5[0][0]                    \n==================================================================================================\nTotal params: 20,849,074\nTrainable params: 20,849,074\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(144, 226, 3, ), name='img')\n",
    "x = layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x1 = layers.Dense(64, activation='relu')(x)\n",
    "gender = layers.Dense(3, name='gender_out')(x1)\n",
    "\n",
    "x2 = layers.Dense(64, activation='relu')(x)\n",
    "tortyp = layers.Dense(3, name='tortyp_out')(x2)\n",
    "\n",
    "x3 = layers.Dense(64, activation='relu')(x)\n",
    "torcol = layers.Dense(11, name='torcol_out')(x3)\n",
    "\n",
    "x4 = layers.Dense(64, activation='relu')(x)\n",
    "legtyp = layers.Dense(3, name='legtyp_out')(x4)\n",
    "\n",
    "x5 = layers.Dense(64, activation='relu')(x)\n",
    "legcol = layers.Dense(11, name='legocol_out')(x5)\n",
    "\n",
    "x6 = layers.Dense(64, activation='relu')(x)\n",
    "luggage = layers.Dense(3, name='luggage_out')(x6)\n",
    "\n",
    "model_cnn = keras.Model(inputs=inputs, outputs=[gender,tortyp,torcol,legtyp,legcol,luggage], name='A1CQ2')\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(loss=['mean_squared_error', keras.losses.SparseCategoricalCrossentropy(from_logits=True)],\n",
    "              optimizer=keras.optimizers.RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-e0a1468d32bf>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-e0a1468d32bf>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    history = model_cnn.fit(train_img, [, y_train],\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "history = model_cnn.fit(train_img, [train_gender, y_train],\n",
    "                    batch_size=64,\n",
    "                    epochs=20,\n",
    "                    validation_data=(x_test_rot, [y_test_rot, y_test]))"
   ]
  }
 ]
}